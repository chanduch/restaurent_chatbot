<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Restaurant AI Chatbot</title>
    <link rel="stylesheet" href="index.css" />
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css"
    />
    <link
      rel="stylesheet"
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap"
    />
  </head>

  <body>
    <header class="header">
      <svg
        class="logo"
        id="restaurant-logo"
        xmlns="http://www.w3.org/2000/svg"
        viewBox="0 0 100 100"
      >
        <defs>
          <pattern
            id="imagePattern"
            patternUnits="userSpaceOnUse"
            width="100"
            height="100"
          >
            <image id="logo-image" x="0" y="0" width="100" height="100"></image>
          </pattern>
        </defs>
        <circle cx="50" cy="50" r="50" fill="url(#imagePattern)"></circle>
      </svg>
      <span class="logo-text">Restaurant Chatbot</span>
      <button
        id="updateMenuBtn"
        class="update-menu-btn"
        onclick="updateMenu()"
        style="display: none"
      >
        Update Menu
      </button>
    </header>

    <div class="control-bar"></div>

    <div id="speakingAvatar" class="speaking-avatar">
      <img src="chatbot-avatar.png" alt="Chatbot Avatar" />
    </div>

    <div class="chat-container">
      <div class="chat-messages" id="chatMessages"></div>
      <div
        id="scrollIndicator"
        class="scroll-indicator"
        onclick="scrollToBottom()"
      >
        <i class="fas fa-chevron-down"></i>
      </div>
      <div class="input-container">
        <div class="input-wrapper">
          <textarea
            id="followUpInput"
            placeholder="Enter your message..."
            rows="2"
          ></textarea>
          <div class="input-buttons">
            <button
              class="icon-button mic-button"
              id="recordButton"
              onclick="toggleRecording()"
            >
              <i class="fas fa-microphone"></i>
            </button>
            <button class="icon-button send-button" onclick="handleFollowUp()">
              <i class="fas fa-paper-plane"></i>
            </button>
          </div>
        </div>
      </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script>
      const API_BASE_URL = `${window.location.protocol}//${window.location.hostname}:${window.location.port}`;
      let isProcessing = false;
      let micPermissionGranted = false;
      let speaking = false;
      let synthesis = window.speechSynthesis;
      let speechSynthesis = window.speechSynthesis;
      let isSpeaking = false;
      let currentUtterance = null;
      let availableVoices = [];
      let voiceMode = false; // Toggle for voice mode

      const urlParams = new URLSearchParams(window.location.search);
      const restaurantName = urlParams.get("restaurant");
      const isAdmin = urlParams.get("admin");

      // Helper functions
      // function resetMicrophoneButton(button, icon, recognition) {
      //     button.classList.remove('recording');
      //     icon.className = 'fas fa-microphone';
      //     if (recognition) {
      //         recognition.stop();
      //     }
      // }

      function showScrollIndicator() {
        const chatMessages = document.getElementById("chatMessages");
        const scrollIndicator = document.getElementById("scrollIndicator");
        scrollIndicator.classList.toggle(
          "visible",
          chatMessages.scrollHeight >
            chatMessages.clientHeight + chatMessages.scrollTop + 100
        );
      }

      function scrollToBottom() {
        const chatMessages = document.getElementById("chatMessages");
        chatMessages.scrollTop = chatMessages.scrollHeight;
        document.getElementById("scrollIndicator").classList.remove("visible");
      }

      async function requestMicrophonePermission() {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({
            audio: true,
          });
          micPermissionGranted = true;
          window.microphoneStream = stream;
          //console.log("Microphone permission granted");
          return true;
        } catch (err) {
          //console.error("Could not get microphone permission:", err);
          return false;
        }
      }

      function updateMenu() {
        if (restaurantName) {
          fetch(`${API_BASE_URL}/update-menu?restaurant=${restaurantName}`)
            .then((response) => {
              if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`);
              }
              return response.json();
            })
            .then((data) => {
              // Add a success message to the UI
              addMessage(
                `Menu for ${restaurantName} updated successfully.`,
                "system"
              );
            })
            .catch((error) => {
              //console.error("Error updating menu:", error);
              addMessage(`Error updating menu: ${error.message}`, "error");
            });
        }
      }

      function toggleVoiceMode() {
        voiceMode = !voiceMode;
        const voiceModeButton = document.getElementById("voiceModeButton");

        if (voiceModeButton) {
          if (voiceMode) {
            voiceModeButton.classList.add("active");
            voiceModeButton.innerHTML = '<i class="fas fa-volume-up"></i>';
          } else {
            voiceModeButton.classList.remove("active");
            voiceModeButton.innerHTML = '<i class="fas fa-volume-mute"></i>';
            stopSpeaking(); // Stop any ongoing speech
          }
        }

        // Save preference to localStorage
        localStorage.setItem("voiceMode", voiceMode.toString());
      }

      function showFollowUpQuestions(followUpQuestions) {
        if (!followUpQuestions || followUpQuestions.length === 0) return;

        const chatMessages = document.getElementById("chatMessages");
        const followUpContainer = document.createElement("div");
        followUpContainer.classList.add("follow-up-container");

        followUpQuestions.forEach((question) => {
          const button = document.createElement("button");
          button.classList.add("follow-up-button");
          button.textContent = question;
          button.onclick = () => handleFollowUp(question);
          followUpContainer.appendChild(button);
        });

        chatMessages.appendChild(followUpContainer);
        chatMessages.scrollTop = chatMessages.scrollHeight; // Ensure scrolling
      }

      function addMessage(message, type, followUpQuestions = null) {
        const chatMessages = document.getElementById("chatMessages");
        const messageDiv = document.createElement("div");

        if (type === "system") {
          // Do not add system messages to the UI
          return;
        }
        if (type === "ai") {
          const container = document.createElement("div");
          container.classList.add("ai-message-container");
          messageDiv.classList.add("message", "ai-message");
          const speakButton = document.createElement("button");
          speakButton.classList.add("speak-button");
          speakButton.innerHTML = '<i class="fas fa-volume-up"></i>';
          speakButton.onclick = () => toggleSpeak(speakButton, message);
          container.appendChild(messageDiv);
          container.appendChild(speakButton);
          chatMessages.appendChild(container);
          // Show scroll indicator after AI response
          showScrollIndicator();
        } else {
          messageDiv.classList.add("message");
          messageDiv.textContent = message;

          if (type === "error") {
            messageDiv.classList.add("error-message");
          } else if (type === "user") {
            messageDiv.classList.add("user-message");
          }
          chatMessages.appendChild(messageDiv);
          // Show scroll indicator after AI response
          showScrollIndicator();
        }

        chatMessages.scrollTop = chatMessages.scrollHeight;
      }

      async function handleFollowUp(question = null) {
        const followUpInput = document.getElementById("followUpInput");
        const prompt = question || followUpInput.value.trim();
        followUpInput.value = "";

        if (!prompt) {
          addMessage("Please enter a message", "error");
          return;
        }

        addMessage(prompt, "user");

        try {
          const requestBody = { prompt };
          const response = await fetch(`${API_BASE_URL}/continue-chat`, {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
            },
            body: JSON.stringify(requestBody),
          });

          const data = await response.json();

          if (!response.ok) {
            throw new Error(data.error || `Server error: ${response.status}`);
          }
          // Call showBotResponse here with parsed data
          showBotResponse(data.response, data.followUpQuestions);
        } catch (error) {
          //console.error("Error:", error);
          addMessage(
            `Error: ${error.message}. Please ensure the server is running and configured correctly.`,
            "error"
          );
        } finally {
          isProcessing = false;
        }
      }

      async function toggleRecording() {
        const button = document.getElementById("recordButton");
        const icon = button.querySelector("i");
        const followUpInput = document.getElementById("followUpInput");
        const avatar = document.getElementById("speakingAvatar");
        let recognition = null;
        if (isProcessing) {
          return;
        }

        function resetMicrophoneButton() {
          button.classList.remove("recording");
          icon.className = "fas fa-microphone";
          if (recognition) {
            recognition.stop();
            recognition = null;
          }
        }

        if (!button.classList.contains("recording")) {
          try {
            if (!micPermissionGranted) {
              const permissionGranted = await requestMicrophonePermission();
              if (!permissionGranted) {
                addMessage(
                  "Please grant microphone access to use voice input.",
                  "error"
                );
                return;
              }
            }

            recognition = new (window.SpeechRecognition ||
              window.webkitSpeechRecognition)();
            recognition.continuous = false;
            recognition.interimResults = false;

            recognition.onstart = () => {
              button.classList.add("recording");
              icon.className = "fas fa-stop";
            };
            recognition.onresult = (event) => {
              const finalTranscript = event.results[0][0].transcript.trim();
              followUpInput.value = finalTranscript;
              resetMicrophoneButton();
              isProcessing = true;

              handleFollowUp(finalTranscript).finally(() => {
                isProcessing = false;
              });
            };
            recognition.onend = () => {
              resetMicrophoneButton();
            };

            recognition.onerror = (event) => {
              //console.error("Speech recognition error:", event.error);
              resetMicrophoneButton();
              if (event.error === "not-allowed") {
                micPermissionGranted = false;
              }
            };

            recognition.start();
          } catch (err) {
            //console.error("Error accessing speech recognition:", err);
            addMessage("Error: Microphone access failed.", "error");
            resetMicrophoneButton();
            micPermissionGranted = false;
          }
        } else {
          resetMicrophoneButton();
        }
      }

      // Function to stop speaking
      function stopSpeaking() {
        if (isSpeaking) {
          speechSynthesis.cancel();
          isSpeaking = false;
          document.getElementById("stopSpeakingButton").style.display = "none";
          currentUtterance = null;

          const avatar = document.getElementById('speakingAvatar');
    if (avatar) {
      avatar.style.display = 'none';
      avatar.classList.remove('speaking');
    }
        }
      }

      // Clean text for better speech synthesis
      function cleanTextForSpeech(text) {
        // Remove code blocks
        text = text.replace(
          /```[\s\S]*?```/g,
          "Code block omitted for speech."
        );

        // Remove markdown formatting
        text = text.replace(/\*\*(.*?)\*\*/g, "$1"); // Bold
        text = text.replace(/\*(.*?)\*/g, "$1"); // Italic
        text = text.replace(/\[(.*?)\]\(.*?\)/g, "$1"); // Links
        text = text.replace(/#{1,6}\s(.*?)(?:\n|$)/g, "$1. "); // Headers

        // Replace bullet points for better speech pauses
        text = text.replace(/- (.*?)(?:\n|$)/g, "$1. ");
        text = text.replace(/\d+\. (.*?)(?:\n|$)/g, "$1. ");

        // Add pauses for better speech flow
        text = text.replace(/\n\n/g, ". ");

        return text;
      }

      // Event listeners and initializations
      document.addEventListener("DOMContentLoaded", () => {
        const speechSupported = checkSpeechSupport();
    
    // Initialize voices if speech is supported
    if (speechSupported) {
        //initializeVoices();
        
        // For mobile Safari (iOS), we need a user interaction to enable speech
        if (/iPhone|iPad|iPod/i.test(navigator.userAgent)) {
            // Create a start button for iOS
            const iosStartButton = document.createElement("button");
            iosStartButton.id = "iosStartButton";
            iosStartButton.className = "control-button";
            iosStartButton.innerHTML = '<i class="fas fa-play"></i> Enable Voice';
            iosStartButton.title = "Enable voice on iOS";
            iosStartButton.onclick = function() {
                // Play a silent utterance to unlock speech synthesis
                const unlockUtterance = new SpeechSynthesisUtterance('');
                unlockUtterance.volume = 0;
                speechSynthesis.speak(unlockUtterance);
                
                // Hide the button after clicking
                this.style.display = "none";
                
                // Show a confirmation message
                addMessage("Voice response enabled!", "system");
            };
            
            // Add to control bar
            const controlBar = document.querySelector(".control-bar");
            if (controlBar) {
                controlBar.appendChild(iosStartButton);
            }
        }
    }

        // For Chrome on any platform - fix the timeout issue
        setInterval(() => {
        if (isSpeaking && speechSynthesis.speaking) {
            speechSynthesis.pause();
            speechSynthesis.resume();
        }
    }, 10000);

        if (restaurantName) {
          document.title = `${restaurantName} Menu AI Chat`;
          const logoText = document.querySelector(".logo-text");
          if (logoText) {
            logoText.textContent = `${restaurantName} Chatbot`;
            document.body.style.backgroundImage = `url('${restaurantName}.png')`;
            const imageUrl = "logo.png";
            document
              .getElementById("logo-image")
              .setAttribute("href", imageUrl);
          }
          localStorage.setItem("restaurantName", restaurantName);
        }

        if (isAdmin) {
          window.location.href = "admin.html";
        }

        updateMenu();
        // Check microphone permissions
        if (navigator.permissions) {
          navigator.permissions
            .query({ name: "microphone" })
            .then((permissionStatus) => {
              // console.log(
              //   "Microphone permission status:",
              //   permissionStatus.state
              // );

              // If already granted, set our flag
              if (permissionStatus.state === "granted") {
                micPermissionGranted = true;
              } else if (permissionStatus.state === "prompt") {
                // If we'll need to ask, do it early
                requestMicrophonePermission();
              }
              // Listen for changes to permission
              permissionStatus.onchange = () => {
                micPermissionGranted = permissionStatus.state === "granted";
                // console.log(
                //   "Permission state changed to:",
                //   permissionStatus.state
                // );
              };
            });
        } else {
          requestMicrophonePermission();
        }

        document
          .getElementById("followUpInput")
          .addEventListener("keydown", function (e) {
            if (e.key === "Enter" && !e.shiftKey) {
              e.preventDefault();
              handleFollowUp();
            }
          });

        document
          .getElementById("chatMessages")
          .addEventListener("scroll", showScrollIndicator);
        const savedVoiceMode = localStorage.getItem("voiceMode");
        if (savedVoiceMode !== null) {
          voiceMode = savedVoiceMode === "true";
        }

        // Create UI elements for voice control if they don't exist
        loadVoices();

        // Initialize voice mode from localStorage
        if (savedVoiceMode !== null) {
          voiceMode = savedVoiceMode === "true";
        }

        //console.log("Initial voice mode:", voiceMode);

        // Set up the voice mode button with correct initial state
        const controlBar = document.querySelector(".control-bar");
        if (controlBar && !document.getElementById("voiceModeButton")) {
          const voiceModeButton = document.createElement("button");
          voiceModeButton.id = "voiceModeButton";
          voiceModeButton.className = "control-button";
          voiceModeButton.innerHTML = voiceMode
            ? '<i class="fas fa-volume-up"></i>'
            : '<i class="fas fa-volume-mute"></i>';
          voiceModeButton.title = "Toggle voice responses";
          voiceModeButton.onclick = toggleVoiceMode;

          // Add active class if voice mode is on
          if (voiceMode) {
            voiceModeButton.classList.add("active");
          }

          controlBar.appendChild(voiceModeButton);
        }

        // Add stop speaking button
        if (controlBar && !document.getElementById("stopSpeakingButton")) {
          const stopSpeakingButton = document.createElement("button");
          stopSpeakingButton.id = "stopSpeakingButton";
          stopSpeakingButton.className = "control-button";
          stopSpeakingButton.innerHTML = '<i class="fas fa-stop"></i>';
          stopSpeakingButton.title = "Stop speaking";
          stopSpeakingButton.onclick = stopSpeaking;
          stopSpeakingButton.style.display = "none";

          controlBar.appendChild(stopSpeakingButton);
        }
      });

      const style = document.createElement("style");
      style.textContent = `
.control-button {
    background: none;
    border: 1px solid #ccc;
    border-radius: 50%;
    width: 40px;
    height: 40px;
    margin: 0 5px;
    cursor: pointer;
    transition: all 0.2s;
}

.control-button:hover {
    background-color: #f0f0f0;
}

.control-button.active {
    background-color: #4285f4;
    color: white;
    border-color: #4285f4;
}

#stopSpeakingButton {
    background-color: #ff4444;
    color: white;
    border-color: #ff4444;
}
`;
      document.head.appendChild(style);
      // I've identified and fixed the following issues:
      // 1. Modified showBotResponse to trigger voice output when voice mode is enabled
      // 2. Fixed issues with the avatar animation during speech
      // 3. Connected the voice system with the message display system
      // 4. Ensured proper coordination between text display and speech

      function showBotResponse(responseText, followUpQuestions) {
        const chatMessages = document.getElementById("chatMessages");

        // Create a new message bubble
        const container = document.createElement("div");
        container.classList.add("ai-message-container");

        const botMessage = document.createElement("div");
        botMessage.classList.add("message", "ai-message");

        const speakButton = document.createElement("button");
        speakButton.classList.add("speak-button");
        speakButton.innerHTML = '<i class="fas fa-volume-up"></i>';
        speakButton.onclick = () => toggleSpeak(speakButton, responseText);

        container.appendChild(botMessage);
        container.appendChild(speakButton);
        chatMessages.appendChild(container);
        // Start voice immediately if voice mode is on
        if (voiceMode) {
          setTimeout(() => {
            //.log("Speaking text:", responseText);
            speakText(responseText);
        }, 100);
        }
        typeText(botMessage, responseText, 30, () => {
          // Show follow-up questions after typing is complete
          showFollowUpQuestions(followUpQuestions);
        });

        // Scroll to the bottom
        chatMessages.scrollTop = chatMessages.scrollHeight;

        // Show scroll indicator
        showScrollIndicator();
      }

      // function showBotResponse(responseText, followUpQuestions) {
      //     const chatMessages = document.getElementById("chatMessages");

      //     // Create a new message bubble
      //     const container = document.createElement("div");
      //     container.classList.add("ai-message-container");

      //     const botMessage = document.createElement("div");
      //     botMessage.classList.add("message", "ai-message");

      //     const speakButton = document.createElement("button");
      //     speakButton.classList.add("speak-button");
      //     speakButton.innerHTML = '<i class="fas fa-volume-up"></i>';
      //     speakButton.onclick = () => toggleSpeak(speakButton, responseText);

      //     container.appendChild(botMessage);
      //     container.appendChild(speakButton);
      //     chatMessages.appendChild(container);

      //     // Start typing effect
      //     typeText(botMessage, responseText, 50, () => {
      //     showFollowUpQuestions(followUpQuestions);
      //     });
      //      // Auto-speak response if voice mode is enabled
      //         if (voiceMode) {
      //           speakText(responseText);
      //         }

      //     // Scroll to the bottom
      //     chatMessages.scrollTop = chatMessages.scrollHeight;

      //     // Show scroll indicator
      //     showScrollIndicator();
      // }

      function typeText(element, text, speed = 25, callback) {
        let index = 0;
        const avatar = document.getElementById("speakingAvatar");

        function type() {
          if (index < text.length) {
            element.innerHTML += text.charAt(index);
            index++;
            setTimeout(type, speed);
          } else if (callback) {
            callback();
            // Don't remove speaking class here if we're going to speak
            // This will be handled by speech events
          }
        }

        if (avatar) {
          avatar.classList.add("speaking");
        }

        type();
      }

      // function typeText(element, text, speed = 25, callback) {
      //   let index = 0;
      //   const avatar = document.getElementById('speakingAvatar');

      //   function type() {
      //     if (index < text.length) {
      //       element.innerHTML += text.charAt(index);
      //       index++;
      //       setTimeout(type, speed);
      //     } else if (callback) {
      //       callback();
      //       // Don't remove speaking class here if we're going to speak
      //       // This will be handled by speech events
      //     }
      //   }

      //   if (avatar) {
      //     avatar.classList.add('speaking');
      //   }

      //   type();
      // }

      // Updated speakText function with debugging and fixes
// function speakText(text) {
//     //.log('Starting speech synthesis with voice mode:', voiceMode);
    
//     // Don't speak if voice mode is off
//     if (!voiceMode) return;
    
//     // Stop any current speech
//     if (isSpeaking) {
//         stopSpeaking();
//     }
    
//     // Set status first
//     isSpeaking = true;
    
//     // Show stop button
//     document.getElementById("stopSpeakingButton").style.display = "inline-block";
    
//     // Show and animate avatar
//     const avatar = document.getElementById("speakingAvatar");
//     if (avatar) {
//         avatar.style.display = "block";
//         avatar.classList.add("speaking");
//     }
    
//     // Clean the text for speech
//     const cleanedText = cleanTextForSpeech(text);
//     //console.log("Prepared text for speech:", cleanedText.substring(0, 50) + "...");
    
//     // Create a new utterance
//     currentUtterance = new SpeechSynthesisUtterance(cleanedText);
    
//     // Load voices and log status
//     if (!availableVoices || availableVoices.length === 0) {
//         //console.log("Loading voices...");
//         availableVoices = speechSynthesis.getVoices();
//         //console.log("Available voices:", availableVoices.length);
//     }
    
//     // Set preferred voice if available
//     if (availableVoices && availableVoices.length > 0) {
//         // First try to find a female English voice
//         let preferredVoice = availableVoices.find(
//             (voice) => voice.lang.includes("en") && voice.name.toLowerCase().includes("female")
//         );
        
//         // If not found, try any English voice
//         if (!preferredVoice) {
//             preferredVoice = availableVoices.find(
//                 (voice) => voice.lang.includes("en")
//             );
//         }
        
//         // If still not found, use the first voice
//         if (!preferredVoice && availableVoices.length > 0) {
//             preferredVoice = availableVoices[0];
//         }
        
//         if (preferredVoice) {
//             //console.log("Using voice:", preferredVoice.name);
//             currentUtterance.voice = preferredVoice;
//         }
//     }
    
//     // Make sure to set these properties before adding event listeners
//     currentUtterance.rate = 1.0;
//     currentUtterance.pitch = 1.0;
//     currentUtterance.volume = 1.0;
    
//     // Add event listeners
//     currentUtterance.onstart = function(event) {
//         //console.log("Speech started successfully");
//         isSpeaking = true;
//     };
    
//     currentUtterance.onend = function(event) {
//         //console.log("Speech ended");
//         isSpeaking = false;
//         document.getElementById("stopSpeakingButton").style.display = "none";
        
//         if (avatar) {
//             avatar.classList.remove("speaking");
//             avatar.style.display = "none"; // Hide the avatar completely when speech ends
//         }
//     };
    
//     currentUtterance.onerror = function(event) {
//         //console.error("Speech synthesis error:", event);
//         isSpeaking = false;
//         document.getElementById("stopSpeakingButton").style.display = "none";
        
//         if (avatar) {
//             avatar.classList.remove("speaking");
//         }
//     };
    
//     // Speech synthesis is actually quite finicky in browsers
//     // This approach works better in most browsers
//     setTimeout(function() {
//         try {
//             //console.log("Attempting to speak...");
//             window.speechSynthesis.cancel(); // Clear any pending speech
//             window.speechSynthesis.speak(currentUtterance);
//             //console.log("Speech command sent to browser");
//         } catch (err) {
//             //console.error("Speech synthesis failed:", err);
//             isSpeaking = false;
//             document.getElementById("stopSpeakingButton").style.display = "none";
            
//             if (avatar) {
//                 avatar.classList.remove("speaking");
//             }
//         }
//     }, 100);
// }

// Modified speakText function with mobile browser compatibility
function speakText(text) {
    console.log('Starting speech synthesis with voice mode:', voiceMode);
    
    // Don't speak if voice mode is off
    if (!voiceMode) return;
    
    // Mobile browser detection
    const isMobile = /iPhone|iPad|iPod|Android/i.test(navigator.userAgent);
    console.log("Is mobile device:", isMobile);
    
    // Stop any current speech
    if (isSpeaking) {
        stopSpeaking();
    }
    
    // Set status first
    isSpeaking = true;
    
    // Show stop button
    document.getElementById("stopSpeakingButton").style.display = "inline-block";
    
    // Show and animate avatar
    const avatar = document.getElementById("speakingAvatar");
    if (avatar) {
        avatar.style.display = "block";
        avatar.classList.add("speaking");
    }
    
    // Clean the text for speech
    const cleanedText = cleanTextForSpeech(text);
    
    // For better mobile compatibility, break text into smaller chunks
    // Mobile browsers often have limitations with long texts
    const maxChunkLength = isMobile ? 150 : 1000;
    const textChunks = [];
    
    // Split text into sentences first
    const sentences = cleanedText.split(/(?<=\.|\?|\!)\s+/);
    let currentChunk = "";
    
    sentences.forEach(sentence => {
        if ((currentChunk + sentence).length <= maxChunkLength) {
            currentChunk += sentence + " ";
        } else {
            if (currentChunk) textChunks.push(currentChunk.trim());
            currentChunk = sentence + " ";
        }
    });
    
    if (currentChunk) textChunks.push(currentChunk.trim());
    
    console.log(`Split speech into ${textChunks.length} chunks`);
    
    // Load voices
    if (!availableVoices || availableVoices.length === 0) {
        availableVoices = speechSynthesis.getVoices();
    }
    
    // Function to speak one chunk
    let chunkIndex = 0;
    function speakNextChunk() {
        if (chunkIndex >= textChunks.length || !isSpeaking) {
            console.log("Finished speaking all chunks");
            setTimeout(() => {
                if (isSpeaking) {
                    isSpeaking = false;
                    document.getElementById("stopSpeakingButton").style.display = "none";
                    
                    if (avatar) {
                        avatar.classList.remove("speaking");
                    }
                }
            }, 500);
            return;
        }
        
        const chunk = textChunks[chunkIndex];
        console.log(`Speaking chunk ${chunkIndex + 1}/${textChunks.length}`);
        
        currentUtterance = new SpeechSynthesisUtterance(chunk);
        
        // Set voice properties
        if (availableVoices && availableVoices.length > 0) {
            // Try to find a suitable voice
            let preferredVoice = null;
            
            // For iOS, use a specific approach
            if (/iPhone|iPad|iPod/i.test(navigator.userAgent)) {
                preferredVoice = availableVoices.find(v => 
                    v.name.includes('Samantha') || v.name.includes('Karen') || 
                    (v.lang.includes('en') && v.name.includes('Female')));
            } else {
                preferredVoice = availableVoices.find(v => 
                    v.lang.includes('en') && 
                    (v.name.includes('Female') || v.name.toLowerCase().includes('female')));
            }
            
            // Fallback to any English voice
            if (!preferredVoice) {
                preferredVoice = availableVoices.find(v => v.lang.includes('en'));
            }
            
            // Last resort: first available voice
            if (!preferredVoice && availableVoices.length > 0) {
                preferredVoice = availableVoices[0];
            }
            
            if (preferredVoice) {
                console.log("Using voice:", preferredVoice.name);
                currentUtterance.voice = preferredVoice;
            }
        }
        
        // Set properties - mobile devices usually need slower speech
        currentUtterance.rate = isMobile ? 0.9 : 1.0;
        currentUtterance.pitch = 1.0;
        currentUtterance.volume = 1.0;
        
        // Handle events
        currentUtterance.onend = function() {
            console.log(`Chunk ${chunkIndex + 1} complete`);
            chunkIndex++;
            // Small delay between chunks for better mobile compatibility
            setTimeout(speakNextChunk, isMobile ? 300 : 50);
        };
        
        currentUtterance.onerror = function(event) {
            console.error(`Error speaking chunk ${chunkIndex + 1}:`, event);
            // Try to recover by moving to the next chunk
            chunkIndex++;
            setTimeout(speakNextChunk, 500);
        };
        
        try {
            speechSynthesis.speak(currentUtterance);
        } catch (err) {
            console.error("Speech synthesis failed:", err);
            // Try to recover
            chunkIndex++;
            setTimeout(speakNextChunk, 500);
        }
    }
    
    // Mobile browsers require user interaction before allowing speech
    // This helps handle that requirement
    if (isMobile) {
        // For iOS Safari specifically
        if (/iPhone|iPad|iPod/i.test(navigator.userAgent)) {
            // Try to use a dummy utterance to unlock speech
            const unlockUtterance = new SpeechSynthesisUtterance('');
            unlockUtterance.volume = 0; // Silent
            unlockUtterance.onend = function() {
                console.log("iOS speech unlocked");
                setTimeout(speakNextChunk, 100);
            };
            speechSynthesis.speak(unlockUtterance);
        } else {
            // For other mobile browsers
            setTimeout(speakNextChunk, 300);
        }
    } else {
        // Desktop browsers
        setTimeout(speakNextChunk, 100);
    }
}
function stopSpeaking() {
    console.log("Stopping speech");
    isSpeaking = false;
    
    // Need to cancel completely for mobile browsers
    window.speechSynthesis.cancel();
    
    document.getElementById("stopSpeakingButton").style.display = "none";
    currentUtterance = null;
    
    const avatar = document.getElementById("speakingAvatar");
    if (avatar) {
        avatar.classList.remove("speaking");
    }
}

// Add this function to detect if the browser supports speech synthesis
function checkSpeechSupport() {
    const support = {
        speechSynthesis: 'speechSynthesis' in window,
        speechSynthesisUtterance: 'SpeechSynthesisUtterance' in window
    };
    
    console.log("Speech synthesis support:", support);
    
    // Enable/disable voice features based on support
    if (!support.speechSynthesis || !support.speechSynthesisUtterance) {
        console.warn("Speech synthesis not supported in this browser");
        // Disable voice mode
        voiceMode = false;
        
        // Hide voice controls
        const voiceModeButton = document.getElementById("voiceModeButton");
        if (voiceModeButton) {
            voiceModeButton.style.display = "none";
        }
        
        const stopSpeakingButton = document.getElementById("stopSpeakingButton");
        if (stopSpeakingButton) {
            stopSpeakingButton.style.display = "none";
        }
        
        // Hide speak buttons on messages
        const speakButtons = document.querySelectorAll(".speak-button");
        speakButtons.forEach(button => {
            button.style.display = "none";
        });
    }
    
    return support.speechSynthesis && support.speechSynthesisUtterance;
}


      // Fixed toggleSpeak function for manual speech button
      function toggleSpeak(button, text) {
        if (isSpeaking) {
          stopSpeaking();
          button.classList.remove("speaking");
          button.innerHTML = '<i class="fas fa-volume-up"></i>';
          return;
        }

        // If not speaking, start speaking
        button.classList.add("speaking");
        button.innerHTML = '<i class="fas fa-stop"></i>';

        // Set up a temporary voice mode
        const savedVoiceMode = voiceMode;
        voiceMode = true;

        // Create speech with an onend callback to reset the button
        speakText(text);

        // Add custom event listener to reset button state
        if (currentUtterance) {
          const originalOnEnd = currentUtterance.onend;
          currentUtterance.onend = (event) => {
            // Call the original onend
            if (originalOnEnd) originalOnEnd(event);

            // Reset button state
            button.classList.remove("speaking");
            button.innerHTML = '<i class="fas fa-volume-up"></i>';

            // Restore saved voice mode
            voiceMode = savedVoiceMode;
          };
        }
      }

      // Clean text for better speech synthesis
      function cleanTextForSpeech(text) {
        // Remove code blocks
        text = text.replace(
          /```[\s\S]*?```/g,
          "Code block omitted for speech."
        );

        // Remove markdown formatting
        text = text.replace(/\*\*(.*?)\*\*/g, "$1"); // Bold
        text = text.replace(/\*(.*?)\*/g, "$1"); // Italic
        text = text.replace(/\[(.*?)\]\(.*?\)/g, "$1"); // Links
        text = text.replace(/#{1,6}\s(.*?)(?:\n|$)/g, "$1. "); // Headers

        // Replace bullet points for better speech pauses
        text = text.replace(/- (.*?)(?:\n|$)/g, "$1. ");
        text = text.replace(/\d+\. (.*?)(?:\n|$)/g, "$1. ");

        // Add pauses for better speech flow
        text = text.replace(/\n\n/g, ". ");

        return text;
      }

      async function handleFollowUp(question = null) {
        const followUpInput = document.getElementById("followUpInput");
        const prompt = question || followUpInput.value.trim();
        followUpInput.value = "";

        if (!prompt) {
          addMessage("Please enter a message", "error");
          return;
        }

        addMessage(prompt, "user");

        try {
          const requestBody = { prompt };
          const response = await fetch(`${API_BASE_URL}/continue-chat`, {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
            },
            body: JSON.stringify(requestBody),
          });

          const data = await response.json();

          if (!response.ok) {
            throw new Error(data.error || `Server error: ${response.status}`);
          }

          // Call showBotResponse here with parsed data
          showBotResponse(data.response, data.followUpQuestions);
        } catch (error) {
          //console.error("Error:", error);
          addMessage(
            `Error: ${error.message}. Please ensure the server is running and configured correctly.`,
            "error"
          );
        } finally {
          isProcessing = false;
        }
      }

      function loadVoices() {
        availableVoices = speechSynthesis.getVoices();
        //console.log("Voices loaded:", availableVoices.length);
      }

      // Initialize voices
      if (speechSynthesis.onvoiceschanged !== undefined) {
        speechSynthesis.onvoiceschanged = loadVoices;
      }

      async function toggleRecording() {
        const button = document.getElementById("recordButton");
        const icon = button.querySelector("i");
        const followUpInput = document.getElementById("followUpInput");
        const avatar = document.getElementById("speakingAvatar");
        let recognition = null;

        if (isProcessing) {
          return;
        }

        function resetMicrophoneButton() {
          button.classList.remove("recording");
          icon.className = "fas fa-microphone";
          if (recognition) {
            recognition.stop();
            recognition = null;
          }
        }

        if (!button.classList.contains("recording")) {
          try {
            if (!micPermissionGranted) {
              const permissionGranted = await requestMicrophonePermission();
              if (!permissionGranted) {
                addMessage(
                  "Please grant microphone access to use voice input.",
                  "error"
                );
                return;
              }
            }

            recognition = new (window.SpeechRecognition ||
            window.webkitSpeechRecognition)();
            recognition.continuous = false;
            recognition.interimResults = false;

            recognition.onstart = () => {
              button.classList.add("recording");
              icon.className = "fas fa-stop";
            };

            recognition.onresult = (event) => {
              const finalTranscript = event.results[0][0].transcript.trim();
              followUpInput.value = finalTranscript;
              resetMicrophoneButton();
              isProcessing = true;

              handleFollowUp(finalTranscript).finally(() => {
                isProcessing = false;
              });
            };

            recognition.onend = () => {
              resetMicrophoneButton();
            };

            recognition.onerror = (event) => {
              //console.error("Speech recognition error:", event.error);
              resetMicrophoneButton();
              if (event.error === "not-allowed") {
                micPermissionGranted = false;
              }
            };

            recognition.start();
          } catch (err) {
            console.error("Error accessing speech recognition:", err);
            addMessage("Error: Microphone access failed.", "error");
            resetMicrophoneButton();
            micPermissionGranted = false;
          }
        } else {
          resetMicrophoneButton();
        }
      }
    </script>
  </body>
</html>
